{
    "seed": 49,
    "batch_size": 4096,
    "lr": 0.0003,
    "num_tokens": 100000000.0,
    "l1_coeff": 0.0,
    "beta1": 0.9,
    "beta2": 0.99,
    "max_grad_norm": 100000,
    "seq_len": 128,
    "dtype": "torch.float32",
    "model_dtype": "torch.float32",
    "model_name": "gpt2-small",
    "site": "resid_pre",
    "layer": 0,
    "act_size": 768,
    "dict_size": 6144,
    "device": "mps",
    "model_batch_size": 32,
    "num_batches_in_buffer": 10,
    "dataset_path": "Skylion007/openwebtext",
    "wandb_project": "gpt2-small-matryoshka-layer0",
    "input_unit_norm": false,
    "perf_log_freq": 1000,
    "sae_type": "global-matryoshka-topk",
    "checkpoint_freq": 5000,
    "n_batches_to_dead": 20,
    "top_k": 32,
    "top_k_aux": 512,
    "aux_penalty": 0.03125,
    "bandwidth": 0.001,
    "hook_point": "blocks.0.hook_resid_pre",
    "name": "gpt2-small_blocks.0.hook_resid_pre_6144_global-matryoshka-topk_32_0.0003",
    "group_sizes": "[768, 768, 1536, 3072]"
}