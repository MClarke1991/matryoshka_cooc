{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_266452/2304816415.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from matryoshka_cooc.subgraph_analysis import (\n",
    "    analyze_subgraph,\n",
    "    load_matryoshka_sae,\n",
    "    load_node_info,\n",
    "    plot_pca_by_feature_activation,\n",
    "    plot_token_pca,\n",
    "    set_device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/matryoshka_cooc')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = Path.cwd().parent.parent\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from matryoshka_cooc.subgraph_analysis import (\n",
    "    analyze_subgraph,\n",
    "    load_matryoshka_sae,\n",
    "    load_node_info,\n",
    "    plot_pca_by_feature_activation,\n",
    "    plot_token_pca,\n",
    "    set_device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-28 18:35:34,032 - INFO - Using device: cuda\n",
      "2025-02-28 18:35:34,032 - INFO - Using device: cuda\n",
      "2025-02-28 18:35:34,032 - INFO - Using device: cuda\n",
      "2025-02-28 18:35:34,033 - INFO - Analyzing subgraph 26 with activation threshold 10.0\n",
      "2025-02-28 18:35:34,033 - INFO - Analyzing subgraph 26 with activation threshold 10.0\n",
      "2025-02-28 18:35:34,033 - INFO - Analyzing subgraph 26 with activation threshold 10.0\n",
      "2025-02-28 18:35:34,034 - INFO - Using device: cuda\n",
      "2025-02-28 18:35:34,034 - INFO - Using device: cuda\n",
      "2025-02-28 18:35:34,034 - INFO - Using device: cuda\n",
      "2025-02-28 18:35:34,589 - INFO - Loaded Matryoshka SAE from /root/matryoshka_cooc/checkpoints/gpt2-small_blocks.8.hook_resid_pre_24576_global-matryoshka-topk_32_0.0003_final.pt\n",
      "2025-02-28 18:35:34,589 - INFO - Loaded Matryoshka SAE from /root/matryoshka_cooc/checkpoints/gpt2-small_blocks.8.hook_resid_pre_24576_global-matryoshka-topk_32_0.0003_final.pt\n",
      "2025-02-28 18:35:34,589 - INFO - Loaded Matryoshka SAE from /root/matryoshka_cooc/checkpoints/gpt2-small_blocks.8.hook_resid_pre_24576_global-matryoshka-topk_32_0.0003_final.pt\n",
      "2025-02-28 18:35:34,591 - INFO - Loading model gpt2-small\n",
      "2025-02-28 18:35:34,591 - INFO - Loading model gpt2-small\n",
      "2025-02-28 18:35:34,591 - INFO - Loading model gpt2-small\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    \"sae_path\": \"checkpoints/gpt2-small_blocks.8.hook_resid_pre_24576_global-matryoshka-topk_32_0.0003_final.pt\",\n",
    "    \"cooc_dir\": \"graph_cooc_n_batches_50_layer_8/matryoshka\",\n",
    "    \"n_batches\": 10,\n",
    "    \"threshold\": 10.0,\n",
    "    \"subgraph_id\": 26,\n",
    "    \"layer\": 8,\n",
    "    \"remove_special_tokens\": True,\n",
    "    \"max_examples\": 500,\n",
    "    \"output_dir\": \"matryoshka_pca_results\",\n",
    "}\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Run analysis\n",
    "analysis_results = analyze_subgraph(\n",
    "    sae_path=root / config[\"sae_path\"],\n",
    "    cooc_dir=root / config[\"cooc_dir\"],\n",
    "    subgraph_id=config[\"subgraph_id\"],\n",
    "    layer=config[\"layer\"],\n",
    "    activation_threshold=config[\"threshold\"],\n",
    "    n_batches=config[\"n_batches\"],\n",
    "    remove_special_tokens=config[\"remove_special_tokens\"],\n",
    "    max_examples=config[\"max_examples\"],\n",
    "    output_dir=config[\"output_dir\"],\n",
    ")\n",
    "\n",
    "# Extract components for later use\n",
    "results = analysis_results[\"results\"]\n",
    "pca_df = analysis_results[\"pca_df\"]\n",
    "pca = analysis_results[\"pca\"]\n",
    "# model = analysis_results[\"model\"]\n",
    "# subgraph_nodes = analysis_results[\"subgraph_nodes\"]\n",
    "\n",
    "# # Store important data in dictionary for easy access\n",
    "# analysis_data = {\n",
    "#     \"pca_df\": pca_df,\n",
    "#     \"tokens\": results[\"all_fired_tokens\"],\n",
    "#     \"contexts\": results[\"all_token_dfs\"].context.values,\n",
    "#     \"reconstructions\": results[\"all_reconstructions\"],\n",
    "#     \"feature_acts\": results[\"all_graph_feature_acts\"],\n",
    "#     \"max_feature_info\": results[\"all_max_feature_info\"],\n",
    "#     \"examples_found\": results[\"all_examples_found\"],\n",
    "#     # \"subgraph_nodes\": subgraph_nodes,\n",
    "#     \"pca_explained_variance\": pca.explained_variance_ratio_\n",
    "#     if pca is not None\n",
    "#     else None,\n",
    "# }\n",
    "\n",
    "# print(f\"Analysis complete! Found {analysis_data['examples_found']} examples\")\n",
    "# if pca is not None:\n",
    "#     print(\"\\nPCA Explained Variance Ratios:\")\n",
    "#     for i, ratio in enumerate(analysis_data[\"pca_explained_variance\"]):\n",
    "#         print(f\"PC{i + 1}: {ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
